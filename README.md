

# Machine Learning
- [Machine Learning](#machine-learning)
  - [*1* 前言](#1-前言)
    - [ChatGPT 原理](#chatgpt-原理)
      - [预训练](#预训练)
      - [微调](#微调)
      - [监督学习](#监督学习)
      - [强化学习](#强化学习)
  - [*2* 预备知识](#2-预备知识)
  - [*3* 线性神经网络](#3-线性神经网络)
  - [*4* 多层感知机](#4-多层感知机)
  - [*5* 深度学习计算](#5-深度学习计算)
  - [*6* 卷积神经网络](#6-卷积神经网络)
  - [*7* 现代卷积神经网络](#7-现代卷积神经网络)
  - [*8* 循环神经网络](#8-循环神经网络)
  - [*9* 现代循环神经网络](#9-现代循环神经网络)
  - [*10* 注意力机制](#10-注意力机制)
    - [Transformer](#transformer)
  - [*11* 优化算法](#11-优化算法)
  - [*12* 计算性能](#12-计算性能)
  - [*13* 计算机视觉](#13-计算机视觉)
  - [*14* 自然语言处理](#14-自然语言处理)
  - [*15* See Also](#15-see-also)

## *1* 前言
### ChatGPT 原理
#### 预训练
- pre-train, self-supervised learning, Foundation model  
- 预训练作用：多语言习得，在一种语言上训练，其他语言自动学习

#### 微调
- Finetune，
- 在 Foundation model 上继续学习

#### 监督学习
- supervised learning，
- 成对的学习资料

#### 强化学习
- reinforcement learning， 
- 不知道标签，只需要判断好坏

## *2* 预备知识
## *3* 线性神经网络
## *4* 多层感知机
## *5* 深度学习计算
## *6* 卷积神经网络
## *7* 现代卷积神经网络
## *8* 循环神经网络
## *9* 现代循环神经网络
## *10* 注意力机制
### Transformer
## *11* 优化算法
## *12* 计算性能
## *13* 计算机视觉
## *14* 自然语言处理



## *15* See Also
- [李宏毅 2023 春机器学习课程](https://speech.ee.ntu.edu.tw/~hylee/ml/2023-spring.php)
- [动手学深度学习](https://zh.d2l.ai/)
- [GitHub of Lhy_Machine_Learning ](https://github.com/Fafa-DL/Lhy_Machine_Learning)
